{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2211b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "from math import sqrt\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "import statsmodels as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.tools.tools import add_constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c55a0",
   "metadata": {},
   "source": [
    "# Bayesian Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1415fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atal_methode(x, grens, HBKRE):\n",
    "    #gegevens HB en KRE uit de literatuur\n",
    "    beta_afwijking = 0.35\n",
    "    if HBKRE == \"HB\":\n",
    "        bio_var = 0.027\n",
    "        analyst_var = 0.0174\n",
    "        var_tussen = 0.059\n",
    "        ondergrens_bio_var = 0.017\n",
    "    else:\n",
    "        bio_var = 0.045\n",
    "        analyst_var = 0.017\n",
    "        var_tussen = 0.141\n",
    "        ondergrens_bio_var = 0.042\n",
    "    \n",
    "    mu_mu = np.mean(grens)\n",
    "    mu_sigma = mu_mu * var_tussen\n",
    "    sigma_mu = mu_mu * np.sqrt(bio_var**2 + analyst_var**2)\n",
    "    sigma_sigma = beta_afwijking * sigma_mu\n",
    "    \n",
    "    minimale_var = sqrt(ondergrens_bio_var**2 + analyst_var**2) * np.mean(x)\n",
    "    \n",
    "    #aanmaken parameter schatters\n",
    "    x_max = np.max(x)\n",
    "    x_min = np.min(x)\n",
    "\n",
    "    if HBKRE == \"HB\":\n",
    "        if x_max - x_min > 2.5:\n",
    "            mu_i = np.linspace(x_min*0.80, x_max*1.20, 30)\n",
    "        else:\n",
    "            mu_i = np.arange(x_min*0.80, x_max*1.21, 0.1)    \n",
    "    else:\n",
    "        if x_max - x_min > 40:\n",
    "            mu_i = np.linspace(x_min*0.80, x_max*1.20, 30)\n",
    "        else:\n",
    "            mu_i = np.arange(x_min*0.80, x_max*1.20 + 1.5, 1.5)\n",
    "        \n",
    "    if HBKRE == \"HB\":\n",
    "        sigma_j = np.linspace(minimale_var, 1.2, 30)\n",
    "    else:\n",
    "        if x_max > 130:\n",
    "            sigma_j = np.linspace(minimale_var, 35, 50)\n",
    "        else:\n",
    "            sigma_j = np.linspace(minimale_var, 12, 30)\n",
    "            \n",
    "    mu, sigma = np.meshgrid(mu_i, sigma_j)\n",
    "    bayes = np.column_stack((mu.ravel(), sigma.ravel()))\n",
    "    \n",
    "    likelihoods = norm.pdf(x[:, np.newaxis], bayes[:,0], bayes[:,1])\n",
    "    bayes_likelihood = np.prod(likelihoods, axis=0)\n",
    "    \n",
    "    #P(mu_i, sigma_j)\n",
    "    #probability van mu sigma uit de a-priori verdeling\n",
    "    prior = norm.pdf(bayes[:,0], loc=mu_mu, scale=mu_sigma) * norm.pdf(bayes[:,1], loc=sigma_mu, scale=sigma_sigma)\n",
    "    \n",
    "    #Vermenigvuldig de bovenstaande kansen\n",
    "    prob = bayes_likelihood * prior\n",
    "    \n",
    "    #De totale kans wordt berekend om de kansen te normaliseren\n",
    "    tot_prob = np.sum(prob)\n",
    "    \n",
    "    #Genormaliseerde kansen\n",
    "    norm_prob = prob / tot_prob\n",
    "\n",
    "    #Nieuwe waarden aanmaken voor probability berekening\n",
    "    if HBKRE == \"HB\":\n",
    "        waarde_nieuw = np.linspace(x_min * 0.75, x_max * 1.25, 40)\n",
    "    else:\n",
    "        waarde_nieuw = np.linspace(x_min * 0.75, x_max * 1.25, 40)\n",
    "    \n",
    "    #Matrix voor elke combinatie van mu en sigma met de mogelijke nieuwe waarden\n",
    "    matrix_waarde_nieuw =  np.zeros((len(bayes), len(waarde_nieuw)))\n",
    "\n",
    "    \n",
    "    #Kansberekening voor elke combinatie van mu en sigma met mogelijke nieuwe waarde\n",
    "    for k, waarde in enumerate(waarde_nieuw):\n",
    "        #iterate over each row of bayes\n",
    "        for j in range(len(bayes)):\n",
    "            matrix_waarde_nieuw[j,k] = norm.pdf(waarde, loc=bayes[j,0], scale=bayes[j,1]) * norm_prob[j]\n",
    "    \n",
    "    #Kansen normaliseren\n",
    "    kansen_waarde_nieuw = np.sum(matrix_waarde_nieuw, axis=0) / np.sum(matrix_waarde_nieuw)\n",
    "    \n",
    "    #Beste parameter schatter\n",
    "    mu_post = np.sum(kansen_waarde_nieuw * waarde_nieuw)\n",
    "    sigma_post = np.sqrt(np.sum(kansen_waarde_nieuw * (waarde_nieuw - mu_post)**2))\n",
    "    \n",
    "    #95% CI van de voorspelling\n",
    "    ondergrens = mu_post-1.96*sigma_post\n",
    "    bovengrens = mu_post+1.96*sigma_post\n",
    "    \n",
    "    res = np.array([ondergrens, bovengrens])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6713e9",
   "metadata": {},
   "source": [
    "# Homeostatic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593420aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dixon_test(data, left=True, right=True):\n",
    "    '''\n",
    "    Dit is een functie voor Dixon test die ik online heb gevonden. \n",
    "    Sebastian Raschka heeft deze op zijn website staan.\n",
    "    Het is overigens belangrijk om te bedenken met welke confidence er gewerkt wordt.\n",
    "    Deze functie is nu gebaseerd op 95% confidence. \n",
    "    Bij wijziging meoten de waarden in Q95 ook aangepast worden\n",
    "    \n",
    "    Keyword arguments:\n",
    "        data = A ordered or unordered list of data points (int or float).\n",
    "        left = Q-test of minimum value in the ordered list if True\n",
    "        right = Q-test of maximum value in the ordered list if True\n",
    "        q_dict = A dictionary of Q-values for a given confidence level,\n",
    "            where the dict. keys are sample sizes N, and the associated values \n",
    "            are the corresponding critical Q values.\n",
    "            \n",
    "    Returns a list of 2 values for the outliers, or None.   \n",
    "    '''\n",
    "    q_dict = {\n",
    "        3: 0.941, 4: 0.765, 5: 0.642, 6: 0.560, 7: 0.507, 8: 0.468, 9: 0.437,\n",
    "        10: 0.412, 11: 0.392, 12: 0.378, 13: 0.361, 14: 0.349, 15: 0.338, 16: 0.329,\n",
    "        17: 0.320, 18: 0.313, 19: 0.306, 20: 0.300, 21: 0.295, 22: 0.290, 23: 0.285,\n",
    "        24: 0.281, 25: 0.277, 26: 0.273, 27: 0.270, 28: 0.267, 29: 0.263, 30: 0.260\n",
    "    } \n",
    "    \n",
    "    assert(left or right), 'At least on of the variables, `left` or `right`, must be True.'\n",
    "    assert(len(data) >= 3), 'At least 3 data points are required'\n",
    "    assert(len(data) <= max(q_dict.keys())), 'Sample size too large'\n",
    "    \n",
    "    sdata = sorted(data)\n",
    "    Q_mindiff, Q_maxdiff = (0, 0), (0, 0)\n",
    "    \n",
    "    if left:\n",
    "        Q_min = (sdata[1] - sdata[0])\n",
    "        try:\n",
    "            Q_min /= (sdata[-1] - sdata[0])\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "        Q_minddiff = (Q_min - q_dict[len(data)], sdata[0])\n",
    "        \n",
    "    if right:\n",
    "        Q_max = abs((sdata[-2] - sdata[-1]))\n",
    "        try:\n",
    "            Q_max /= abs((sdata[0] - sdata[-1]))\n",
    "        except ZeroDivisionError:\n",
    "            pass\n",
    "            Q_maxdiff = (Q_max - q_dict[len(data)], sdata[-1])\n",
    "    \n",
    "    if not Q_mindiff[0] > 0 and not Q_maxdiff[0] > 0:\n",
    "        outliers = [None, None]\n",
    "        \n",
    "    elif Q_mindiff[0] == Q_maxdiff[0]:\n",
    "        outliers = [Q_mindiff[1], Q_maxdiff[1]]\n",
    "        \n",
    "    elif Q_mindiff[0] > Q_maxdiff[0]:\n",
    "        outliers = [Q_mindiff[1], None]\n",
    "        \n",
    "    else:\n",
    "        outliers = [None, Q_maxdiff[1]]\n",
    "        \n",
    "    return outliers\n",
    "    \n",
    "\n",
    "def coskun_methode(y):\n",
    "    alpha = 0.05\n",
    "    y = np.array(y)\n",
    "    y_non_na = y[~np.isnan(y)]\n",
    "    n = len(y_non_na)\n",
    "    \n",
    "    if n >= 3 and np.all(y_non_na != 0):\n",
    "        x = np.arange(1, (n + 1))\n",
    "        \n",
    "        #linear regression\n",
    "        x_with_const = add_constant(x)\n",
    "        model = OLS(y_non_na, x_with_const).fit(method='qr')\n",
    "        \n",
    "        slope = model.params[1]\n",
    "        #calculate alternative steyx (instead of model.bse[1]) to match R approach\n",
    "        steyx = np.sqrt(np.sum(model.resid**2)/ model.df_resid)\n",
    "        \n",
    "        #confidence intervals based on residual standard error\n",
    "        s_ll = slope - steyx\n",
    "        s_ul = slope + steyx\n",
    "        \n",
    "        #trend: s_ll * s_ul\n",
    "        trend = s_ll * s_ul\n",
    "        \n",
    "        #Dixon test for outliers\n",
    "        try:\n",
    "            outliers = dixon_test(y_non_na)\n",
    "            has_outlier = any(outliers)\n",
    "            if has_outlier:\n",
    "                y_non_na = y_non_na[~np.isin(y_non_na, outliers)]\n",
    "                dix_res = f'Outliers are present, obs y={outlier_value} are removed'\n",
    "            else:\n",
    "                dix_res = \"No outliers at 5% significance level\"\n",
    "        except ValueError as e:\n",
    "            return {\n",
    "                'LL': np.nan,\n",
    "                'UL': np.nan,\n",
    "                'Range': np.nan,\n",
    "                'trend_test': str(e),\n",
    "                'out_test': str(e)\n",
    "            }\n",
    "\n",
    "        \n",
    "        #Check if trend is present\n",
    "        if s_ll <= 0 <= s_ul:\n",
    "            #Compute reference intervals\n",
    "            tvset = stats.t.ppf(1-(alpha/2), df=n-1) * np.sqrt((n+1)/n) * np.std(y_non_na, ddof=1)\n",
    "            ll = np.mean(y_non_na) - tvset\n",
    "            ul = np.mean(y_non_na) + tvset\n",
    "            range_ri = ul - ll\n",
    "            trend_res = \"Trend is not present\"\n",
    "        else:\n",
    "            ll = ul = range_ri = np.nan\n",
    "            trend_res = \"Trend is present - intervals are not computed\"\n",
    "        \n",
    "    else:\n",
    "        ll = ul = range_i = npp.nan\n",
    "        trend_res = \"Not computed, n <  3\"\n",
    "        dix_res = \"Not computed, n < 3\"\n",
    "        \n",
    "    return ll, ul, range_ri, trend_res, dix_res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2945079e",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915386a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df):\n",
    "    results = []\n",
    "    \n",
    "    #iteratie over unieke metingen (HB en KRE)\n",
    "    for HBKRE in df['meting'].unique():\n",
    "        print(f'Verwerking {HBKRE} metingen...')\n",
    "        \n",
    "        sub_group = df[df['meting'] == HBKRE]\n",
    "        aantal_patients = len(sub_group['patientID'].unique())\n",
    "        huidige_patient_teller = 0\n",
    "\n",
    "        #iteratie over unieke patienten \n",
    "        for patient in sub_group['patientID'].unique():\n",
    "            huidige_patient_teller += 1\n",
    "            print(f'    Verwerking patient {huidige_patient_teller} van {aantal_patients}...')\n",
    "            \n",
    "            patient_data = sub_group[sub_group.patientID == patient]\n",
    "            x = patient_data['meetresultaat'].values \n",
    "            bestaande_interval = patient_data[['lg', 'rg']].iloc[0]\n",
    "\n",
    "            #Atal methode toepassen (bayesiaans)\n",
    "            ondergrens_atal, bovengrens_atal = atal_methode(x, bestaande_interval, HBKRE)\n",
    "\n",
    "            results.append(pd.Series({\n",
    "                'patient': patient,\n",
    "                'meting': HBKRE, \n",
    "                'methode': 'ATAL',\n",
    "                'ondergrens': ondergrens_atal,\n",
    "                'bovengrens': bovengrens_atal\n",
    "            }))\n",
    "\n",
    "            #Coskun methode toepassen (homeostasis)\n",
    "            ondergrens_coskun, bovengrens_coskun, _, _, _  = coskun_methode(x)\n",
    "\n",
    "            results.append(pd.Series({\n",
    "                'patient': patient,\n",
    "                'meting': HBKRE, \n",
    "                'methode': 'COSKUN',\n",
    "                'ondergrens': ondergrens_coskun,\n",
    "                'bovengrens': bovengrens_coskun\n",
    "            }))\n",
    "\n",
    "\n",
    "    print('Pipeline verwerking compleet!')\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1475ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv').drop(['Unnamed: 0'], axis=1)\n",
    "df.datum_meting = pd.to_datetime(df.datum_meting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pipeline(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76967f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
